{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:97% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:97% !important; }</style>\"))\n",
    "\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "\n",
    "import scoring as score # para hacer los reportes de puntajes\n",
    "from time import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, RandomizedSearchCV, ShuffleSplit, train_test_split\n",
    "\n",
    "properati = pd.read_csv('datos/properati_final.csv',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136356 entries, 0 to 136355\n",
      "Data columns (total 23 columns):\n",
      "created_on                    136356 non-null object\n",
      "property_type                 136356 non-null object\n",
      "place_name                    136356 non-null object\n",
      "state_name                    136356 non-null object\n",
      "lat-lon                       136356 non-null object\n",
      "lat                           96345 non-null float64\n",
      "lon                           96345 non-null float64\n",
      "price                         136356 non-null float64\n",
      "currency                      136356 non-null object\n",
      "price_aprox_local_currency    136356 non-null float64\n",
      "price_aprox_usd               136356 non-null float64\n",
      "surface_total_in_m2           136356 non-null float64\n",
      "surface_covered_in_m2         136356 non-null float64\n",
      "price_usd_per_m2              136356 non-null float64\n",
      "price_per_m2                  136356 non-null float64\n",
      "floor                         14295 non-null float64\n",
      "rooms                         69632 non-null float64\n",
      "expenses                      25390 non-null float64\n",
      "properati_url                 136356 non-null object\n",
      "description                   136352 non-null object\n",
      "title                         136356 non-null object\n",
      "fecha                         136356 non-null object\n",
      "superficie_descubierta        90183 non-null float64\n",
      "dtypes: float64(13), object(10)\n",
      "memory usage: 23.9+ MB\n"
     ]
    }
   ],
   "source": [
    "properati.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparo las columnas a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cant_buckets = 500\n",
    "\n",
    "#buckets\n",
    "cantidad,rango = np.histogram(properati['price_usd_per_m2'], bins=cant_buckets)\n",
    "properati['categories_by_price']=pd.cut(properati['price_usd_per_m2'],rango,labels=np.arange(cant_buckets))\n",
    "properati['price_range']=pd.cut(properati['price_usd_per_m2'],rango)\n",
    "#lo casteo a float porque si no tira error \n",
    "properati['categories_by_price']=properati['categories_by_price'].astype(np.float64) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busco una aproximacion de hiper-parametros con random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#paso features con strings a numericos\n",
    "le_barrio = preprocessing.LabelEncoder()\n",
    "barrios=properati['state_name']\n",
    "le_barrio.fit(barrios)\n",
    "properati['state_name'] = le_barrio.transform(barrios)\n",
    "\n",
    "le_zona = preprocessing.LabelEncoder()\n",
    "zona=properati['place_name']\n",
    "le_zona.fit(zona)\n",
    "properati['place_name'] = le_zona.transform(zona)\n",
    "\n",
    "le_tipo = preprocessing.LabelEncoder()\n",
    "tipos_prop=properati['property_type']\n",
    "le_tipo.fit(tipos_prop)\n",
    "properati['property_type'] = le_tipo.transform(tipos_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/_base.py:194: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/_base.py:194: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/_base.py:194: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n"
     ]
    }
   ],
   "source": [
    "%%notify\n",
    "\n",
    "#preparo set de datos\n",
    "X = zip(properati['surface_total_in_m2'],\\\n",
    "        properati['surface_covered_in_m2'],properati['property_type'],properati['state_name'],properati['place_name'])\n",
    "y = properati['price_aprox_usd']\n",
    "\n",
    "scaler = preprocessing.Normalizer()\n",
    "\n",
    "X=scaler.fit_transform(X,y)\n",
    "\n",
    "perceptron = MLPRegressor()\n",
    "\n",
    "# Utility function to report best scores\n",
    "solver = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "activation =[\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "alpha = np.arange(0.0001,0.01,0.0001)\n",
    "\n",
    "param_grid = {\"alpha\": alpha, \"solver\": solver,\"activation\":activation}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)\n",
    "\n",
    "# run randomized search\n",
    "random_search = RandomizedSearchCV(perceptron, param_distributions=param_grid,\n",
    "n_iter=20,cv=5,n_jobs=-1) #refit=False es para poder usar multiscoring\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"RandomizedSearchCV duro %.2f segundos para %d candidatos a hiper-parametros.\"\n",
    "    % (time() - start, len(random_search.cv_results_['params'])))\n",
    "print(\"\")\n",
    "score.report_single(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busco mas detalladamente los hiper-parametros en el rango de los mejores resultados con Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%notify\n",
    "\n",
    "#preparo set de datos\n",
    "X = zip(properati['dist_a_subte'],properati['dist_a_univ'])\n",
    "y = properati['categories_by_price']\n",
    "\n",
    "perceptron = Perceptron(n_jobs=-1)\n",
    "        \n",
    "alpha=np.arange(0.2,0.5,0.01)\n",
    "pen =['l2','elasticnet']\n",
    "param_grid = {\"alpha\": alpha, \"penalty\": pen}\n",
    "\n",
    "custom_cv = ShuffleSplit(n_splits=5, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)\n",
    "\n",
    "grid_search = GridSearchCV(perceptron,param_grid=param_grid,cv=custom_cv)\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "    % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "score.report_single(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mejor_rf = grid_search.best_estimator_\n",
    "print mejor_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errores = mejor_rf.predict(X_test)-y_test\n",
    "print (\"Error maximo:{0}\\nError minimo:{1}\".format( max(abs(errores)),min(abs(errores))))\n",
    "print(errores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_max=0\n",
    "max_error=100\n",
    "lista=[]\n",
    "for error in errores:\n",
    "    if abs(error)>max_error:\n",
    "        count_max+=1\n",
    "        lista.append(abs(error))\n",
    "count_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the histogram of the data\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.hist(errores, 100, facecolor='blue')\n",
    "plt.xlabel('Errores')\n",
    "plt.ylabel('Cantidad')\n",
    "#plt.xlim(-1000, 1000) #para variar el \"zoom a 0\"\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
