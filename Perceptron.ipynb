{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:97% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:97% !important; }</style>\"))\n",
    "\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "\n",
    "import scoring as score # para hacer los reportes de puntajes\n",
    "from time import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, RandomizedSearchCV, ShuffleSplit, train_test_split\n",
    "\n",
    "properati = pd.read_csv('datos/caba_para_mapa.csv',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparo las columnas a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cant_buckets = 500\n",
    "\n",
    "#buckets\n",
    "cantidad,rango = np.histogram(properati['price_usd_per_m2'], bins=cant_buckets)\n",
    "properati['categories_by_price']=pd.cut(properati['price_usd_per_m2'],rango,labels=np.arange(cant_buckets))\n",
    "properati['price_range']=pd.cut(properati['price_usd_per_m2'],rango)\n",
    "#lo casteo a float porque si no tira error \n",
    "properati['categories_by_price']=properati['categories_by_price'].astype(np.float64) \n",
    "\n",
    "#tenia un nan nose porque\n",
    "properati.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busco una aproximacion de hiper-parametros con random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "%%notify\n",
    "\n",
    "#preparo set de datos\n",
    "X = zip(properati['dist_a_subte'],properati['dist_a_univ'],properati['dist_a_tren'],properati['dist_a_villa'],\\\n",
    "        properati['dist_a_zona_anegada'],properati['surface_total_in_m2'],\\\n",
    "        properati['surface_covered_in_m2'],properati['lat'],properati['lon'])\n",
    "y = properati['categories_by_price']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "scaler2= MinMaxScaler()\n",
    "\n",
    "X=scaler.fit_transform(X,y)\n",
    "X=scaler2.fit_transform(X,y)\n",
    "\n",
    "perceptron = Perceptron(n_jobs=-1)\n",
    "\n",
    "scoring={\"accuracy\":\"accuracy\"} # defino diccionario para varios scorings\n",
    "\n",
    "# Utility function to report best scores\n",
    "alpha=np.arange(0.000001,1,0.000001)\n",
    "pen =['l2','l1','elasticnet']\n",
    "param_grid = {\"alpha\": alpha, \"penalty\": pen}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)\n",
    "\n",
    "# run randomized search\n",
    "random_search = RandomizedSearchCV(perceptron, param_distributions=param_grid,\n",
    "n_iter=100,cv=5) #refit=False es para poder usar multiscoring\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"RandomizedSearchCV duro %.2f segundos para %d candidatos a hiper-parametros.\"\n",
    "    % (time() - start, len(random_search.cv_results_['params'])))\n",
    "print(\"\")\n",
    "score.report_multi(random_search.cv_results_,scoring.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busco mas detalladamente los hiper-parametros en el rango de los mejores resultados con Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%notify\n",
    "\n",
    "#preparo set de datos\n",
    "X = zip(properati['dist_a_subte'],properati['dist_a_univ'])\n",
    "y = properati['categories_by_price']\n",
    "\n",
    "perceptron = Perceptron(n_jobs=-1)\n",
    "        \n",
    "alpha=np.arange(0.2,0.5,0.01)\n",
    "pen =['l2','elasticnet']\n",
    "param_grid = {\"alpha\": alpha, \"penalty\": pen}\n",
    "\n",
    "custom_cv = ShuffleSplit(n_splits=5, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)\n",
    "\n",
    "grid_search = GridSearchCV(perceptron,param_grid=param_grid,cv=custom_cv)\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "    % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "score.report_single(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_rf = grid_search.best_estimator_\n",
    "print mejor_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errores = mejor_rf.predict(X_test)-y_test\n",
    "print (\"Error maximo:{0}\\nError minimo:{1}\".format( max(abs(errores)),min(abs(errores))))\n",
    "print(errores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_max=0\n",
    "max_error=100\n",
    "lista=[]\n",
    "for error in errores:\n",
    "    if abs(error)>max_error:\n",
    "        count_max+=1\n",
    "        lista.append(abs(error))\n",
    "count_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the histogram of the data\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.hist(errores, 100, facecolor='blue')\n",
    "plt.xlabel('Errores')\n",
    "plt.ylabel('Cantidad')\n",
    "#plt.xlim(-1000, 1000) #para variar el \"zoom a 0\"\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
